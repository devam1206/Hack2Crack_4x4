{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflask\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rowcol\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from rasterio.transform import rowcol\n",
    "from pyproj import Transformer, CRS\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "def get_raster_values(lat, lon, raster_paths, default_crs=\"EPSG:32643\"):\n",
    "    results = {}\n",
    "\n",
    "    for raster_path in raster_paths:\n",
    "            with rasterio.open(raster_path) as dataset:\n",
    "                dataset_crs = dataset.crs if dataset.crs else CRS.from_string(default_crs)\n",
    "\n",
    "                transformer = Transformer.from_crs(\"EPSG:4326\", dataset_crs, always_xy=True)\n",
    "                x, y = transformer.transform(lon, lat)\n",
    "                row, col = rowcol(dataset.transform, x, y)\n",
    "\n",
    "                value = dataset.read(1)[row, col]\n",
    "\n",
    "                min_val = dataset.read(1).min()\n",
    "                max_val = dataset.read(1).max()\n",
    "                \n",
    "                # Extract filename without extension and store the value\n",
    "                file_name = os.path.splitext(os.path.basename(raster_path))[0]\n",
    "                \n",
    "                if file_name == 'meanticd':\n",
    "                    file_name = \"inorganic_carbon_density\"\n",
    "                elif file_name == 'meantocd':\n",
    "                    file_name = \"organic_carbon_density\"\n",
    "            \n",
    "                elif file_name =='fsalt':\n",
    "                    file_name = \"salt_affected\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "                elif file_name =='fwatero':\n",
    "                    file_name = \"water_erosion\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "                elif file_name =='fwindero':\n",
    "                    file_name = \"wind_erosion\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "                elif file_name =='fwaterlog':\n",
    "                    file_name = \"water_logging\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "\n",
    "                elif file_name.startswith('ffallow'):\n",
    "                    file_name = \"fallow\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "                elif file_name.startswith('fkharif'):\n",
    "                    file_name = \"kharif\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "                elif file_name.startswith('frabi'):\n",
    "                    file_name = \"rabi\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "                elif file_name.startswith('fnsa'):\n",
    "                    file_name = \"net_sown_area\"\n",
    "                    value = (value - min_val) / (max_val - min_val) * 100\n",
    "                \n",
    "                elif file_name.startswith('rootsm'):\n",
    "                    file_name = \"root_level_surface_moisture\"\n",
    "                elif file_name.startswith('s_runoff'):\n",
    "                    file_name = \"surface_runoff\"\n",
    "                elif file_name.startswith('upSMNRSC'):\n",
    "                    file_name = \"upper_level_surface_moisture\"\n",
    "                elif file_name.startswith('ocm2_vf'):\n",
    "                    file_name = \"vegetation_fraction\"\n",
    "                elif file_name.startswith('ocm2_ndvi_filt'):\n",
    "                    file_name = \"filtered_ndvi\"\n",
    "                elif file_name.startswith('localocm2'):\n",
    "                    file_name = \"local_ndvi\"\n",
    "                elif file_name.startswith('globalocm2'):\n",
    "                    file_name = \"global_ndvi\"\n",
    "                elif file_name.startswith('evaNHP'):\n",
    "                    file_name = \"evapotranspiration\"\n",
    "\n",
    "                results[file_name] = float(round(value, 2))\n",
    "\n",
    "    return results\n",
    "\n",
    "def classes_data(raster_values):\n",
    "    new_dict={}\n",
    "\n",
    "    soil_keys = (\"floamy\", \"fclayey\", \"fclayskeletal\", \"fsandy\")\n",
    "    soil_values = {key: raster_values.get(key, 0) for key in soil_keys}\n",
    "    max_soil_type = max(soil_values, key=soil_values.get)\n",
    "    \n",
    "    soil_depth_keys = (\n",
    "        \"fsoildep0_25\", \"fsoildep25_50\", \"fsoildep50_75\",\n",
    "        \"fsoildep75_100\", \"fsoildep100_150\", \"fsoildep150_200\"\n",
    "    )\n",
    "    soil_depth_values = {key: raster_values.get(key, 0) for key in soil_depth_keys}\n",
    "    max_soil_depth = max(soil_depth_values, key=soil_depth_values.get)\n",
    "    \n",
    "    for key in list(raster_values.keys()):  \n",
    "        if key not in soil_keys and key not in soil_depth_keys:\n",
    "            new_dict[key] = raster_values[key]\n",
    "\n",
    "    new_dict['soil_type'] = max_soil_type[1:]\n",
    "\n",
    "    match = re.search(r\"(\\d+)_(\\d+)\", max_soil_depth)\n",
    "    if match:\n",
    "        start, end = match.groups()\n",
    "        soil_depth = f\"{start}-{end}m\"\n",
    "\n",
    "    new_dict['soil_depth'] = soil_depth\n",
    "    \n",
    "    new_dict['organic_carbon_density'] = round(new_dict['organic_carbon_density'],2)\n",
    "    new_dict['inorganic_carbon_density'] = round(new_dict['inorganic_carbon_density'],2)\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "def fetch_weather_data(lat, lon, years=5, delay=0):\n",
    "    today = datetime.date.today() - datetime.timedelta(days=5)  # Adjust start date to 5 days prior\n",
    "    start_year = today.year - years \n",
    "    end_year = today.year  \n",
    "    \n",
    "    all_data = []\n",
    "    for year in range(start_year, end_year):\n",
    "        start_date = f\"{year}-{today.month:02d}-{today.day:02d}\"\n",
    "        end_date = f\"{year + 1}-{today.month:02d}-{today.day:02d}\" \n",
    "\n",
    "        url = (f\"https://archive-api.open-meteo.com/v1/archive?latitude={lat}&longitude={lon}\"\n",
    "               f\"&start_date={start_date}&end_date={end_date}\"\n",
    "               f\"&daily=temperature_2m_max,temperature_2m_min,precipitation_sum,relative_humidity_2m_mean\"\n",
    "               f\"&timezone=auto\")\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            if (\"daily\" in data and \n",
    "                \"time\" in data[\"daily\"] and \n",
    "                \"temperature_2m_max\" in data[\"daily\"] and \n",
    "                \"temperature_2m_min\" in data[\"daily\"] and \n",
    "                \"precipitation_sum\" in data[\"daily\"]):\n",
    "                \n",
    "                dates = data[\"daily\"][\"time\"]\n",
    "                temp_max = data[\"daily\"][\"temperature_2m_max\"]\n",
    "                temp_min = data[\"daily\"][\"temperature_2m_min\"]\n",
    "                rainfall = data[\"daily\"][\"precipitation_sum\"]\n",
    "\n",
    "                if \"relative_humidity_2m_mean\" in data[\"daily\"]:\n",
    "                    humidity = data[\"daily\"][\"relative_humidity_2m_mean\"]\n",
    "                else:\n",
    "                    humidity = [None] * len(dates)\n",
    "                    print(\"Humidity data not available\")\n",
    "                \n",
    "                for i in range(len(dates)):\n",
    "                    if temp_max[i] is not None and temp_min[i] is not None:\n",
    "                        avg_temp = (temp_max[i] + temp_min[i]) / 2\n",
    "                    else:\n",
    "                        avg_temp = None\n",
    "\n",
    "                    rain_val = rainfall[i] if rainfall[i] is not None else None\n",
    "                    hum_val = humidity[i] if i < len(humidity) else None\n",
    "                    \n",
    "                    all_data.append([dates[i], avg_temp, rain_val, hum_val])\n",
    "            else:\n",
    "                print(f\"Missing required data fields for {year}\")\n",
    "                print(f\"Available fields: {data.get('daily', {}).keys()}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for {year}: {response.status_code}\")\n",
    "            print(f\"Error message: {response.text}\") \n",
    "        \n",
    "        # Add delay between requests to avoid rate limiting\n",
    "        if delay > 0 and year < end_year - 1:  # Don't delay after the last request\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data, columns=[\"date\", \"Temperature\", \"Rainfall\", \"Humidity\"])\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data collected\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "\n",
    "def forecast_lstm(df, forecast_periods=365, seq_length=10, epochs=50, batch_size=32):\n",
    "    forecast_start_date = df.index[-1] + pd.Timedelta(days=1)\n",
    "    future_dates = pd.date_range(start=forecast_start_date + pd.Timedelta(days=1), \n",
    "                                periods=forecast_periods)\n",
    "    forecast_df = pd.DataFrame(index=future_dates)\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(df[column].values.reshape(-1, 1))\n",
    "        \n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled_data) - seq_length):\n",
    "            X.append(scaled_data[i:(i + seq_length), 0])\n",
    "            y.append(scaled_data[i + seq_length, 0])\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        \n",
    "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        models[column] = model\n",
    "        \n",
    "        predictions = []\n",
    "        current_batch = scaled_data[-seq_length:].reshape(1, seq_length, 1)\n",
    "        \n",
    "        for i in range(forecast_periods):\n",
    "            current_pred = model.predict(current_batch, verbose=0)[0]\n",
    "            \n",
    "            predictions.append(current_pred[0])\n",
    "            \n",
    "            current_batch = np.append(current_batch[:, 1:, :], \n",
    "                                     [[current_pred]], \n",
    "                                     axis=1)\n",
    "            \n",
    "        predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "        forecast_df[column] = predictions\n",
    "    \n",
    "    return forecast_df, models\n",
    "\n",
    "\n",
    "def create_interactive_plots(df, output_file=\"weather.html\"):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.set_index('Unnamed: 0', inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    date_values = df.index\n",
    "    \n",
    "    fig = sp.make_subplots(\n",
    "        rows=3, cols=1, \n",
    "        subplot_titles=('Air Temperature (°C)', 'Precipitation (mm)', 'Atmospheric Humidity (%)'),\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_values, y=df['Temperature'], mode='lines', name='Air Temperature', line=dict(color='red', width=3)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_values, y=df['Rainfall'], mode='lines', name='Precipitation', line=dict(color='blue', width=3)),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=date_values, y=df['Humidity'], mode='lines', name='Atmospheric Humidity', line=dict(color='green', width=3)),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=900,\n",
    "        plot_bgcolor=\"white\",\n",
    "        xaxis=dict(showgrid=True, gridcolor=\"lightgray\"),\n",
    "        yaxis=dict(title=\"Temperature (°C)\", showgrid=True, gridcolor=\"lightgray\"),\n",
    "        xaxis2=dict(showgrid=True, gridcolor=\"lightgray\"),\n",
    "        yaxis2=dict(title=\"Rainfall (mm)\", showgrid=True, gridcolor=\"lightgray\"),\n",
    "        xaxis3=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor=\"lightgray\",\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=9, label=\"9m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=12, label=\"1y\", step=\"month\", stepmode=\"backward\"),\n",
    "                ]),\n",
    "                x=0.5,\n",
    "                y=-0.15\n",
    "            ),\n",
    "            type=\"date\"\n",
    "        ),\n",
    "        yaxis3=dict(title=\"Humidity (%)\", showgrid=True, gridcolor=\"lightgray\"),\n",
    "        margin=dict(l=50, r=50, t=50, b=50),\n",
    "    )\n",
    "    \n",
    "    output_folder = \"output\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    output_path = os.path.join(output_folder, output_file)\n",
    "    fig.write_html(output_path)\n",
    "\n",
    "\n",
    "@app.route('/get_data', methods=['GET'])\n",
    "def get_data():\n",
    "    lat = request.args.get('lat', type=float)\n",
    "    lon = request.args.get('lon', type=float)\n",
    "\n",
    "    forecast_period=120\n",
    "\n",
    "    weather_df = fetch_weather_data(lat, lon, delay=2) \n",
    "\n",
    "    weather_df.set_index(\"date\", inplace=True)\n",
    "    weather_df.index = pd.to_datetime(weather_df.index)\n",
    "    forecast_df, models = forecast_lstm(weather_df,forecast_periods=forecast_period)\n",
    "    \n",
    "    create_interactive_plots(forecast_df)\n",
    "    weather_graph_path=\"output/weather.html\"\n",
    "\n",
    "    avg_temperature = forecast_df['Temperature'].mean()\n",
    "    avg_humidity = forecast_df['Humidity'].mean()\n",
    "    avg_rainfall = forecast_df['Rainfall'].mean()\n",
    "    \n",
    "    if lat is None or lon is None:\n",
    "        return jsonify({\"error\": \"Missing lat or lon parameters\"}), 400\n",
    "    \n",
    "    folder_path = \"gis_data\"\n",
    "    raster_files = glob.glob(os.path.join(folder_path, \"*.asc\")) + glob.glob(os.path.join(folder_path, \"*.tif\"))\n",
    "    raster_values = get_raster_values(lat, lon, raster_files, \"EPSG:32643\")\n",
    "    raster_values = classes_data(raster_values)\n",
    "\n",
    "    raster_values['avg_temperature'] = round(float(avg_temperature),2)\n",
    "    raster_values['avg_humidity'] = round(float(avg_humidity),2)\n",
    "    raster_values['avg_rainfall'] = round(float(avg_rainfall),2)\n",
    "    raster_values['weather_graph_path'] = weather_graph_path\n",
    "\n",
    "    return jsonify(raster_values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True,port=7000)\n",
    "\n",
    "# @app.route('/get_data', methods=['POST'])\n",
    "# def get_data():\n",
    "#     data = request.get_json()\n",
    "#     lat = data.get('lat')\n",
    "#     lon = data.get('lon')\n",
    "#     if lat is None or lon is None:\n",
    "#         return jsonify({\"error\": \"Missing lat or lon parameters\"}), 400\n",
    "#     folder_path = \"gis_data\"\n",
    "#     raster_files = glob.glob(os.path.join(folder_path, \"*.asc\")) + glob.glob(os.path.join(folder_path, \"*.tif\"))\n",
    "#     raster_values = get_raster_values(lat, lon, raster_files, \"EPSG:32643\")\n",
    "#     raster_values = classes_data(raster_values)\n",
    "#     return jsonify(raster_values)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
